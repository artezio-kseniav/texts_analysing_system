Title Information Technology — Big Data — Overview and Vocabulary. Working Draft v2 stage. Foreword ISO (the International Organization for Standardization) is a worldwide federation of national standards bodies (ISO member bodies). The work of preparing International Standards is normally carried out through ISO technical committees. Each member body interested in a subject for which a technical committee has been established has the right to be represented on that committee. International organizations, governmental and non-governmental, in liaison with ISO, also take part in the work. ISO collaborates closely with the International Electrotechnical Commission (IEC) on all matters of electrotechnical standardization. The procedures used to develop this document and those intended for its further maintenance are described in the ISO/IEC Directives, Part 1. In particular the different approval criteria needed for the different types of ISO documents should be noted. This document was drafted in accordance with the editorial rules of the ISO/IEC Directives, Part 2.  www.iso.org/directives Attention is drawn to the possibility that some of the elements of this document may be the subject of patent rights. ISO shall not be held responsible for identifying any or all such patent rights. Details of any patent rights identified during the development of the document will be in the Introduction and/or on the ISO list of patent declarations received.  www.iso.org/patents Any trade name used in this document is information given for the convenience of users and does not constitute an endorsement. For an explanation on the meaning of ISO specific terms and expressions related to conformity assessment, as well as information about ISO's adherence to the WTO principles in the Technical Barriers to Trade (TBT) see the following URL: Foreword - Supplementary information The committee responsible for this document is ISO/JTC1 Information Technology, Working Group WG9, Big Data. Introduction The Big Data paradigm is a rapidly changing field with rapidly changing technologies. This standard will provide the normative definitions and the vocabulary needed to promote improved communication and understanding of this emerging area. The ISO/IEC JTC1 WG9 on Big data decided that the normative content of this document would benefit greatly at this time with another informative document that provided context for the creation of 20546, as well as discussion of the concepts ascribed to Big Data that are not in fact new to Big Data. The technical report will provide the conceptual overview of the emerging field of Big Data, its relationship to other technical areas and standards efforts, and the concepts ascribed to big data that are not new to Big Data. The technical report is expected to be time sensitive and will need revision over time.   Title Information technology — Big data — Overview and vocabulary 1 Scope This International Standard provides an overview of Big Data along with a set of terms and definitions. It provides a terminological foundation for Big Data-related standards. 2 Normative references The following documents, in whole or in part, are normatively referenced in this document and are indispensable for its application. For dated references, only the edition cited applies. For undated references, the latest edition of the referenced document (including any amendments) applies.   3 Terms and Abbreviations 3.1 Terms Defined elsewhere This document uses the following terms defined elsewhere. Editor’s Note: As the Reference Architecture evolves, and the Section 4.x overview paragraphs are filled in, the only 3.1 terms that will be kept will be those useful to the 4.x discussions – 22 Nov 2015  3.1.1 cluster computing system in which components located on networked computers communicate and coordinate their actions by passing messages  Editor’s note: from N0011 – we should find this in existing parallel computing standards Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015   3.1.2 distributed computing computing system in which components located on networked computers communicate and coordinate their actions by passing messages  Editor’s note: from N0011 – we should find this in existing parallel computing standards 3.1.3 massively parallel processing the use of a large number of processors (or separate computers) to perform a set of coordinated computations in parallel (simultaneously).  Editor’s note: from N0011 – we should find this in existing parallel computing standards  3.1.4 distributed file systems multi-structured (object)datasets that are distributed across the computing nodes of the server cluster(s) Editor’s note: from N0011 – we should find this in existing parallel computing standards Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 3.1.5 shared-nothing architecture a distributed computing architecture in which each node is independent and self-sufficient, and there is no single point of contention across the system) 3.1.6 capability quality of being able to perform a given activity  [SOURCE: ISO 15531-1:2004] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015  3.1.7 cloud computing paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on-demand [SOURCE: ISO/IEC 17788:2014] 3.1.8 framework structure expressed in diagrams, text, and formal rules which relates the components of a conceptual entity to each other  [SOURCE: ISO 17185-1:2014] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 3.1.9 Internet of Things  integrated environment, inter-connecting anything, anywhere at anytime [SOURCE: ISO/IEC JTC 1 SWG 5 Report:2013] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 3.1.10 lifecycle evolution of a system, product, service, project or other human-made entity from conception through retirement  [SOURCE: ISO/IEC/TR 29110-1:2011] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 3.1.11 ownership legal right of possession, including the right of disposition, and sharing in all the risks and profits commensurate with the degree of ownership interest or shareholding, as demonstrated by an examination of the substance, rather than the form, of ownership arrangements [SOURCE: ISO 10845-5:2011] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015  3.1.12 provenance information on the place and time of origin or derivation or a resource or a record or proof of authenticity or of past ownership [SOURCE: ISO 19153:2014] 3.1.13 relational model data model whose structure is based on a set of relations [SOURCE: ISO/IEC 2382-17:1999] 3.1.14 repository collection of all software-related artefacts belonging to a system or the location/format in which such a collection is stored [SOURCE: ISO/IEC IEEE 24765:2010] 3.1.15 security all aspects related to defining, achieving, and maintaining confidentiality, integrity, availability, non-repudiation, accountability, authenticity, and reliability of a system [SOURCE: ISO/IEC 15288:2008] Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 reference N0124 - JP04 – 22 Nov 2015  3.1.16 information security Preservation of confidentiality, integrity and availability of information.  NOTE – In addition, other properties, such as authenticity, accountability, non-repudiation, and reliability can also be involved.  [SOURCE: ISO/IEC 17789] Editor’s note: from N0124 - JP04 – 22 Nov 2015  3.1.17  confidentiality Property that information is not made available or disclosed to unauthorized individuals, entities, or processes  [SOURCE: ISO/IEC 17789] Editor’s note: from N0124 - JP04 – 22 Nov 2015  3.1.18 integrity Property of accuracy and completeness.  [SOURCE: ISO/IEC 17789] Editor’s note: from N0124 - JP04 – 22 Nov 2015  3.1.19  availability Property of being accessible and usable upon demand by an authorized entity.  [SOURCE: ISO/IEC 17789] Editor’s note: from N0124 - JP04 – 22 Nov 2015   3.1.21 sensor device that observes and measures a physical property of a natural phenomenon or man-made process and converts that measurement into a signal [SOURCE: ISO/IEC 29182-2:2013] 3.1.22 smart grid electric grid system, which is characterized by the use of communication networks and the control of grid components and loads [SOURCE: ISO/IEC/TR 27019:2013] 3.1.23 streaming data data passing across an interface from a source that is operating continuously  [SOURCE: ISO/IEC 19784-4:2011] 3.1.24 traceability property that allows the tracking of the activity of an identity, process, or an element throughout the supply chain    3.2 Terms Defined in this International Standard  3.2.1 big data extensive datasets primarily in the characteristics of volume, variety, velocity, and/or variability that require a scalable architecture for efficient storage, manipulation, and analysis  Editor’s note: from N0011 Note 1 to entry: Big Data is used as the name of the solution that handles big data extensive datasets.  Editor’s note: from N0063  3.2.2 horizontal scaling coordination of individual resources (e.g. server) that are integrated to act in parallel  Editor’s note: from N0011  3.2.3 vertical scaling the use of greater clock speeds, IO bandwidth and storage capabilities to build higher performing systems Editor’s note: from N0011 3.2.3 big data paradigm distribution of data systems across horizontally-coupled independent resources to achieve the scalability needed for the efficient processing of extensive datasets  Editor’s note: from N0011 3.2.5 big data engineering advanced techniques that harness independent resources for building scalable data systems when the characteristics of the datasets require new architectures for efficient storage, manipulation, and analysis Editor’s note: from N0011 Storage and data manipulation technologies that leverage a collection of horizontally coupled resources to achieve a nearly linear scalability in performance Editor’s note: from ISO/IEC JTC1 Information technology - Big data – preliminary report 2014 3.2.6 big data analytics analytical functions to support the integration of results derived in parallel across distributed pieces of one or more data sources.  Note: This is a rapidly evolving field both in terms of functionality and the underlying programming model Editor’s note: from ISO/IEC JTC1 Information technology - Big data – preliminary report 2014 3.2.7 big data models logical data models (relational and non-relational) and processing/computation models (batch, streaming, and transactional) for the storage and manipulation of data across horizontally scaled resources Editor’s note: from ISO/IEC JTC1 Information technology - Big data – preliminary report 2014 3.2.8 non-relational models NoSQL Logical data models that do not follow relational algebra for the storage and manipulation of data Note: NoSQL is the term in common usage, which is typically translated as “no-SQL” or “not only SQL”, even though SQL languages are being developed for them Editor’s note: from N0011  3.2.9 key-value datastore TBD  Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 reference N0124 - JP05 – 22 Nov 2015  3.2.10 document datastore TBD Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 reference N0124 - JP05 – 22 Nov 2015  3.2.11 graphical datastore TBD  Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 reference N0124 - JP05 – 22 Nov 2015  3.2.12 sparse table datastore TBD  Editor’s Note: Leave Place-holder to see if it’s needed for context 22 Nov 2015 reference N0124 - JP05 – 22 Nov 2015  3.2.13 schema-on-read application of a data schema when the data is queried, not prior to storage of the data Editor’s note: from N0011  3.3 Abbreviations 3.3.1 NoSQL no SQL or not only SQL Editor’s note: from N0124 - JP06 – 22 Nov 2015 3.3.2 MPP massively parallel processing  4 Overview of Big Data Editor’s Note: Type text here - use subclauses if required e.g. 4.1 or 4.1.1. For example: 4.1 General Discussion The term Big Data implies data that is extensive in volume, velocity, or variety. The term does not, however, represent data that is simply bigger than before, since this has happened on a regular basis for decades. The specific occurrence that has led to the widespread usage of this term is that these extensive datasets can no longer be handled in traditional data system architectures. The term big data implies the paradigm shift to use distributed, scalable computing for data-intensive systems to achieve the needed performance efficiency at an affordable cost. In the evolution of data systems, there have been a number of times when the need for efficient, cost effective data analysis has forced a change in existing technologies. For example, the move to a relational model occurred when methods to reliably handle changes to structured data led to the shift toward a data storage paradigm that modelled relational algebra. That was a fundamental shift in data handling. The current revolution in technologies referred to as Big Data has arisen because the relational data model can no longer efficiently handle all the current needs for analysis of large and often unstructured datasets. It is not just that data is bigger than before, as it has been steadily getting larger for decades. The Big Data revolution is instead a one-time fundamental shift in architecture, just as the shift to the relational model was a one-time shift. As relational databases evolved to greater efficiencies over decades, so too will Big Data technologies continue to evolve. Many of the conceptual underpinnings of Big Data have been around for years, but the last decade has seen an explosion in their maturation and application to scaled data systems 4.2 Big Data Concepts The term Big Data is overloaded in common usage, and is commonly used to represent a number of related concepts, in part because several distinct dimensions are consistently interacting with each other. To understand this revolution, the interplay of the following aspects must be considered: the characteristics of the datasets, the analysis of the datasets, the performance of the systems that handle the data, the business considerations of cost effectiveness, and the new technical field of engineering and analysis techniques for distributed processing across nodes. <Editor’s Note: from N0111 2015-04-09> •	field of study  •	irregular or heterogeneous data structures, their navigation, query, and datatyping •	computation parallelism and its management during deployment or execution •	descriptive data and self-inquiry about objects for real-time decision-making •	presentation and aggregation of data that exceed visual limitations of a single page <Editor’s Note: List Discussed in Meeting during presentation of N0105 2015-04-09> •	Large, fast-moving, diverse datasets (volume, velocity, variety) •	Distributed data-intensive computing (conceptually similar to massively parallel processing) •	New logical data models (NoSQL) – including key-value, document, graphical •	Learning directly from data (Data Science)  4.2.1 volume Volume is the characteristic of data at rest that is most associated with Big Data. Estimates show that the amount of data in the world doubles every two years.  Should this trend continue, by 2020 there would be 500 times the amount of data as existed in 2011. 4.2.2 velocity Velocity is the rate of flow at which the data is created, stored, analysed or visualized. Big Data velocity means a large quantity of data is being processed in a short amount of time. 4.2.3 variety Variety represents the need to analyse across a number of data domains and a number of data types. Traditionally, a variety of data was handled through transformations or pre-analytics to extract features that would allow integration with other data. The wider range of data formats, logical models, timescales, and semantics, which is desirous to use in analytics, complicates the integration of the variety of data. 4.2.4 variability  4.2.5 scatter-gather processing large data sets with a parallel, distributed algorithm on a cluster. Note: MapReduce is an implementation of a scatter-gather process for data processing Editor’s note: don’t know if we should define a term that refers to a specific implementation 4.2.6 big data platform the application of a scatter-gather data transformation across a distributed data file system Note: Hadoop is an implementation of a big data platform 4.2.7 computational portability the  movement of the computation to the location of the data Note: related to the prior concept of agents 4.2.8 data science the extraction of actionable knowledge directly from data through a process of discovery, or  hypothesis and hypothesis testing. 4.2.9 Big Data Field The term Big Data is often used to refer to a new field of study, that encompasses Big Data engineering, data science, and data platforms  4.3 Additional Related Concepts Additional concepts are equated to Big Data, which in fact are not new and are not unique to this new Big Data paradigm.  While Big Data changes the scale of the activity, it does not change it in kind. <Editor’s Note: List Discussed in Meeting during presentation of N0105 2015-04-09> •	Use of unstructured data (image, audio, video, documents) •	Loss of privacy (due to big data integration) •	Distribution of Data Ownership •	New value to society 4.3.1 value Value represents the benefit to the organization of the actionable knowledge derived from an analytic system. This term is not new to big data, but is often ascribed to Big Data due to the understanding that data has intrinsic value that was typically not considered previously.   4.3.2 veracity Veracity refers to the completeness and accuracy of the data and relates to the data quality issues in existence for a long time. If the analytics are causal, then the quality of every data element is extremely important. If the analytics are correlations or trending over massive volume datasets, then individual bad elements could be lost in the overall counts and the trend will still be accurate 4.3.3 unstructured data  Unstructured data types, such as text, image, video, and relationship data, have been increasing in both volume and prominence. While modern relational databases tend to have support for these types of data elements, their ability to directly analyze, index, and process them has tended to be both limited and accessed via non-standard SQL extensions. The need to analyze unstructured or semi-structured data has been present for many years. However, the Big Data paradigm shift has increased the emphasis on the value of unstructured or relationship data, and also on different engineering methods that can handle data more efficiently. 5 Cross-Cutting Concepts of Big Data Editor’s Note: This section will discuss the relationship to other topic areas. 5.1 metadata Editor’s Note: This section will discuss the relationship to ISO/IEC ??? – 22 Nov 2015  5.2 analytics Editor’s Note: This section will discuss the relationship to TC69 activities – 22 Nov 2015  5.3 cloud computing Cloud computing is a paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual resources with self-service provisioning and administration on demand. There are several key characteristics often present in for cloud computing deployments including: broad network access, measured service, multi-tenancy, on-demand self-service, rapid elasticity and scalability, and resource pooling. Cloud computing is an accepted infrastructure model for development of a Big Data system. Most Big Data functional components are provided by Cloud computing, helping systems achieve characteristics of volume, velocity, and variety. Customers may develop their own Big Data system on top of PaaS or IaaS, or use Big Data service via SaaS.  Editor’s note: from N0124 - JP07 – 22 Nov 2015 Editor’s Note: This section will discuss the relationship to ISO/IEC 17789 – 22 Nov 2015  5.4 security Editor’s Note: This section will discuss the relationship to ISO/IEC ??? – 22 Nov 2015  5.5 privacy Integrating datasets can result in the creation of personally identifiable information (PII) even when PII this was not present in the individual datasets. This problem pre-dated the big data regime. For small sample sizes, it has been shown in a number of cases that individuals can be identified from their activity, for example in health datasets or in movies watched. This concern is heightened now that so much data is available about individuals on the web and in social media.  5.6 SQL SQL (Structured Query Language) is a standard interactive and programming language designed for querying, updating, and managing data and data set in the database management system.  SQL was first published as ISO International Standard (ISO/IEC 9075) in 1987, and it has been revised to include a larger set of features as the query language for Information technology.  SQL is designed for manipulating structured data, and it is also fast becoming the default language for big data analytics. SQL provides a mature and comprehensive framework for data access supporting a broad range of advanced analytical features. Analytics is a must-have functional component of data warehouse and big data. Modern SQL databases support the discovery of columns across a wide range of data set: not only relational table/views, but also XML, JSON, spatial objects, image-style objects (Binary Large Objects and Character Large Objects), and semantic objects Editor’s note: from N0124 - JP07 – 22 Nov 2015 Editor’s Note: This section will discuss the relationship to ISO/IEC ??? – 22 Nov 2015 5.7 parallel computing Editor’s Note: This section will discuss the relationship to ISO/IEC ??? – 22 Nov 2015  5.8 Internet of Things  5.9 programming languages Editor’s Note: This section will discuss the relationship to ISO/IEC ??? – 22 Nov 2015    6 Relevant Standards Activities Editor’s Note: This section will discuss the relationship to specific standards described in Section 5 above in cross-cutting concepts – 22 Nov 2015 Type text here - use subclauses if required e.g. 6.1 or 6.1.1. 6.1 Standards Relationships	 Type text here - use subclauses if required e.g. 6.1 or 6.1.1. 6.1.1 Parallel Computing Editor’s Note: haven’t found the specific relevant standards yet – 22 Nov 2015  6.1.1 Cloud Computing ISO/IEC 17788 Information technology — Cloud Computing — Overview and Vocabulary ISO/IEC 17789 Information technology — Cloud Computing — Reference architecture   6.1.2 Internet of Things ISO/IEC 20941 Information technology — Internet of Things — Definition and Vocabulary ISO/IEC 30141 Information technology — Internet of Things — Internet of Things Reference architecture (IoT RA)  6.1.3 SQL Editor’s Note: haven’t found the specific relevant standards yet – 22 Nov 2015  6.1.4 Smart Cities Editor’s Note: haven’t found the specific relevant standards yet – 22 Nov 2015  6.2 Potential Gaps or extensions needed in Standards  Type text here - use subclauses if required e.g. 6.1 or 6.1.1.   Annex A (informative) Relevant Reports A.1 Related ISO\IEC Standards Type text here - use subclauses if required e.g. A.1.1 or A.1.1.1. A.1.1 ISO/IEC 17788:2014, Information technology — Cloud computing – Overview and vocabulary A.1.2 ISO\IEC JTC1 Information technology Big data – preliminary report 2014 A.2 Guiding ISO\IEC Documents A.2.1 ISO 704:200, Terminology work – Principles and methods A.2.2 ISO 860:2007 Terminology work – Harmonization of concepts and terms A.2.3 ISO 1087-1:2000, Terminology work -- Vocabulary -- Part 1: Theory and application A.2.4 ISO 10241-1:2011 Terminology entries in standards – Part 1: General Requirements and examples of presentation A.2.5 ISO 10241-2:2011 Terminology entries in standards – Part 2: Adoption of standardised terminological entries A.2.6 JTC 1 SD 20 JTC 1 IT Vocabulary Maintenance Team Best Practices Guide.