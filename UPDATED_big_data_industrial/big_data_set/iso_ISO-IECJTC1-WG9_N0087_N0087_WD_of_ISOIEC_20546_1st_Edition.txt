Information Technology – Big Data – Overview and Vocabulary (Updates after July WG9 F2F Meeting in Spain). ISO (the International Organization for Standardization) is a worldwide federation of national standards bodies (ISO member bodies). The work of preparing International Standards is normally carried out through ISO technical committees. Each member body interested in a subject for which a technical committee has been established has the right to be represented on that committee. International organizations, governmental and non-governmental, in liaison with ISO, also take part in the work. ISO collaborates closely with the International Electrotechnical Commission (IEC) on all matters of electrotechnical standardization. The procedures used to develop this document and those intended for its further maintenance are described in the ISO/IEC Directives, Part 1. In particular the different approval criteria needed for the different types of ISO documents should be noted. This document was drafted in accordance with the editorial rules of the ISO/IEC Directives, Part 2.  www.iso.org/directives Attention is drawn to the possibility that some of the elements of this document may be the subject of patent rights. ISO shall not be held responsible for identifying any or all such patent rights. Details of any patent rights identified during the development of the document will be in the Introduction and/or on the ISO list of patent declarations received.  www.iso.org/patents Any trade name used in this document is information given for the convenience of users and does not constitute an endorsement. For an explanation on the meaning of ISO specific terms and expressions related to conformity assessment, as well as information about ISO's adherence to the WTO principles in the Technical Barriers to Trade (TBT) see the following URL: Foreword - Supplementary information The committee responsible for this document is ISO/JTC1 Information Technology, Working Group WG9, Big Data. The Big Data paradigm is a rapidly changing field with rapidly changing technologies. This standard will provide the normative definitions and the vocabulary needed to promote improved communication and understanding of this emerging area. The ISO/IEC JTC1 WG9 on Big data decided that the normative content of this document would benefit greatly at this time with another informative document that provided context for the creation of 20546, as well as discussion of the concepts ascribed to Big Data that are not in fact new to Big Data. The technical report will provide the conceptual overview of the emerging field of Big Data, its relationship to other technical areas and standards efforts, and the concepts ascribed to big data that are not new to Big Data. The technical report is expected to be time sensitive and will need revision over time. This International Standard provides an overview of Big Data along with a set of terms and definitions. It provides a terminological foundation for Big Data-related standards. The following documents, in whole or in part, are normatively referenced in this document and are indispensable for its application. For dated references, only the edition cited applies. For undated references, the latest edition of the referenced document (including any amendments) applies. The term Big Data implies data that is extensive in volume, velocity, or variety. The term does not, however, represent data that is simply bigger than before, since this has happened on a regular basis for decades. The specific occurrence that has led to the widespread usage of this term is that these extensive datasets can no longer be handled in traditional data system architectures. The term big data implies the paradigm shift to use distributed, scalable computing for data-intensive systems to achieve the needed performance efficiency at an affordable cost. In the evolution of data systems, there have been a number of times when the need for efficient, cost effective data analysis has forced a change in existing technologies. For example, the move to a relational model occurred when methods to reliably handle changes to structured data led to the shift toward a data storage paradigm that modelled relational algebra. That was a fundamental shift in data handling. The current revolution in technologies referred to as Big Data has arisen because the relational data model can no longer efficiently handle all the current needs for analysis of large and often unstructured datasets. It is not just that data is bigger than before, as it has been steadily getting larger for decades. The Big Data revolution is instead a one-time fundamental shift in architecture, just as the shift to the relational model was a one-time shift. As relational databases evolved to greater efficiencies over decades, so too will Big Data technologies continue to evolve. Many of the conceptual underpinnings of Big Data have been around for years, but the last decade has seen an explosion in their maturation and application to scaled data systems. The term Big Data is overloaded in common usage, and is commonly used to represent a number of related concepts, in part because several distinct dimensions are consistently interacting with each other. To understand this revolution, the interplay of the following aspects must be considered: the characteristics of the datasets, the analysis of the datasets, the performance of the systems that handle the data, the business considerations of cost effectiveness, and the new technical field of engineering and analysis techniques for distributed processing across nodes. Volume is the characteristic of data at rest that is most associated with Big Data. Estimates show that the amount of data in the world doubles every two years.  Should this trend continue, by 2020 there would be 500 times the amount of data as existed in 2011. Velocity is the rate of flow at which the data is created, stored, analysed or visualized. Big Data velocity means a large quantity of data is being processed in a short amount of time. Variety represents the need to analyse across a number of data domains and a number of data types. Traditionally, a variety of data was handled through transformations or pre-analytics to extract features that would allow integration with other data. The wider range of data formats, logical models, timescales, and semantics, which is desirous to use in analytics, complicates the integration of the variety of data. The term Big Data is often used to refer to a new field of study, that encompasses Big Data engineering, data science, and data platforms. Additional concepts are equated to Big Data, which in fact are not new and are not unique to this new Big Data paradigm.  While Big Data changes the scale of the activity, it does not change it in kind.  Value represents the benefit to the organization of the actionable knowledge derived from an analytic system. This term is not new to big data, but is often ascribed to Big Data due to the understanding that data has intrinsic value that was typically not considered previously. Veracity refers to the completeness and accuracy of the data and relates to the data quality issues in existence for a long time. If the analytics are causal, then the quality of every data element is extremely important. If the analytics are correlations or trending over massive volume datasets, then individual bad elements could be lost in the overall counts and the trend will still be accurate. Unstructured data types, such as text, image, video, and relationship data, have been increasing in both volume and prominence. While modern relational databases tend to have support for these types of data elements, their ability to directly analyze, index, and process them has tended to be both limited and accessed via non-standard SQL extensions. The need to analyze unstructured or semi-structured data has been present for many years. However, the Big Data paradigm shift has increased the emphasis on the value of unstructured or relationship data, and also on different engineering methods that can handle data more efficiently. A.1 Related ISO\IEC Standards Type text here - use subclauses if required e.g. A.1.1 or A.1.1.1. A.1.1 ISO/IEC 17788:2014, Information technology — Cloud computing – Overview and vocabulary A.1.2 ISO\IEC JTC1 Information technology Big data – preliminary report 2014 A.2 Guiding ISO\IEC Documents A.2.1 ISO 704:200, Terminology work – Principles and methods A.2.2 ISO 860:2007 Terminology work – Harmonization of concepts and terms A.2.3 ISO 1087-1:2000, Terminology work -- Vocabulary -- Part 1: Theory and application A.2.4 ISO 10241-1:2011 Terminology entries in standards – Part 1: General Requirements and examples of presentation A.2.5 ISO 10241-2:2011 Terminology entries in standards – Part 2: Adoption of standardised terminological entries A.2.6 JTC 1 SD 20 JTC 1 IT Vocabulary Maintenance Team Best Practices Guide, Executive Summary (JTC 1 N 12090).