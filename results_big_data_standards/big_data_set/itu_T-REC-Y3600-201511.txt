SERIES Y: GLOBAL INFORMATION  INFRASTRUCTURE, INTERNET PROTOCOL ASPECTS  AND NEXT-GENERATION NETWORKS. Cloud Computing. Big data – Cloud computing based requirements  and capabilities. Recommendation ITU-T Y.3600. Recommendation  ITU-T  Y.3600  provides  requirements,  capabilities  and  use  cases  of  cloud  computing based big data as well as its system context. Cloud computing based big data provides the  capabilities to collect, store,  analyse,  visualize and  manage varieties of large volume datasets, which  cannot be rapidly transferred and analysed using traditional technologies. Keywords: Big data, big data ecosystem, cloud computing, data analytics, data storage, real-time analysis. The International Telecommunication Union (ITU) is  the United Nations specialized agency in the field of  telecommunications,  information  and  communication  technologies  (ICTs).  The  ITU  Telecommunication  Standardization Sector (ITU-T) is a permanent organ of ITU. ITU-T is responsible for studying technical,  operating  and  tariff  questions  and  issuing  Recommendations  on  them  with  a  view  to  standardizing  telecommunications on a worldwide basis. The  World  Telecommunication  Standardization  Assembly  (WTSA),  which  meets  every  four  years,  establishes  the  topics  for  study  by  the  ITU-T  study  groups  which,  in  turn,  produce  Recommendations  on  these topics. The approval of ITU-T Recommendations is covered by the procedure laid down in WTSA Resolution 1. In  some  areas  of  information  technology  which  fall  within  ITU -T's  purview,  the  necessary  standards  are  prepared on a collaborative basis with ISO and IEC. ITU  draws  attention  to  the  possibility  that  the  practice  or  implementation  of  this  Recommendation  may  involve  the  use  of  a  claimed  Intellectual  Property  Right.  ITU  takes  no  position  concerning  the  evidence,  validity or applicability of claimed Intellectual Property Rights, whether asserted by ITU members or others  outside of the Recommendation development process. As  of  the  date  of  approval  of  this  Recommendation,  ITU  had  received  notice  of  intellectual  property,  protected by patents, which may be required to implement this Recommendation. However, implementers  are cautioned that this may not represent the latest information and are therefore strongly urged to consult the  TSB patent database.    This Recommendation provides an approach to use cloud computing to meet  existing  challenges in  the use of big data. This Recommendation addresses the following subjects. Overview of big data. Introduction to big data. Big data ecosystem and roles. Relationship between cloud computing and big data. Cloud computing based big data system context and benefits. Cloud computing based big data requirements. Cloud computing based big data capabilities. Note that use cases of cloud computing based big data are provided in Appendix I and II. The  following  ITU-T  Recommendations  and  other  references  contain  provisions  which,  through  reference in this text, constitute provisions of  this Recommendation. At the time of publication, the  editions indicated were  valid. All Recommendations and other references are subject to  revision;  users of this Recommendation are therefore encouraged to investigate the possibility of applying the  most  recent  edition  of  the  Recommendations  and  other  references  listed  below.  A  list  of  the  currently valid ITU-T Recommendations is regularly published. The reference to a document within  this Recommendation does not give it, as a stand-alone document, the status of a Recommendation. The keywords  "is  required  to"  indicate a requirement which must be strictly followed and from  which no deviation is permitted if conformance to this document is to be claimed.  The keywords  "is recommended"  indicate a requirement which is recommended but which is not  absolutely required. Thus this requirement need not be present to claim conformance. The  keywords  "can  optionally"  indicate  an  optional  requirement  which  is  permissible,  without  implying  any  sense  of  being  recommended.  This  term  is  not  intended  to  imply  that  the  vendor 's  implementation must provide the option and the feature can be optionally enabled by the network  operator/service provider.  Rather, it means the vendor may optionally provide the feature and still  claim conformance with the specification. In the body of this document and its annexes, the words shall, shall not, should, and may sometimes  appear, in which case they are to be interpreted, respectively, as is required to, is prohibited from, is  recommended, and can optionally. The appearance of such phrases or keywords in an appendix or  in material explicitly marked as informative are to be interpreted as having no normative intent. With  the  rapid  development  of  information  and  communications  technology  (ICT),  Internet  technologies  and  services,  huge  amounts  of  data  are  generated,  transmitted  and  stored  at  an  explosive rate of growth.  Data are generated by many sources and not only  by  sensors, cameras or  network  devices,  but  also  by  web  pages,  email  systems  and  social  networks  as  well  as  by  many  other  sources.  Datasets are becoming so large and so complex or are arriving so fast that traditional  data  processing  methods  and  tools  are  inadequate.  Efficient  analytics  of  data  within  tolerable  elapsed times becomes very challenging. The paradigm being developed to resolve the above issues  is called big data. For the purpose of this Recommendation it is understood, that within  the  big  data ecosystem, data  types include structured, semi-structured and unstructured data. Structured data are often stored in  databases which may be organized in different models, such as relational models, document models,  key-value models, graph models, etc. Semi-structured data does not conform to the formal structure  of data models, but contain tags or markers to identify data.  Unstructured data do not have a predefined  data  model  and  are  not  organized  in  any  defined  manner.  Within  all  data  types  data  can  exist in formats, such as text, spreadsheet, video, audio, image, map, etc. Big  data  are  successfully  used  in  many  fields,  if  traditional  methods  and  tools  have  become  inefficient, where data processing is characterized by scale (volume), diversity (variety), high speed  (velocity)  and  possibly  other  criteria  like  credibility  (veracity)  or  business  value.  These  characteristics, usually called the Vs, can be explained as follows. Volume: refers to the amount of data collected, stored, analysed and visualized, which big  data technologies need to resolve. Variety:  refers  to  different  data  types  and  data  formats  that  are  processed  by  big  data  technologies. Velocity:  refers  to  both  how  fast  the  data  is  being  collected  and  how  fast  the  data  is  processed by big data technologies to deliver expected results. NOTE  –  Additionally, veracity refers to  the  uncertainty of  the  data and value refers to the business results  from the gains in new information using big data technologies. Other Vs can be considered as well. Taking  into  account  the  above  Vs'  described  characteristics,  big  data  technologies  and  services  allow many new challenges to be resolved and also create more new opportunities than ever before.  Heterogeneity and incompleteness:  Data processed using big data can miss some attributes  or introduce noise in data transmission. Even after data cleaning and error correction, some  incompleteness  and  some  errors  in  data  are  likely  to  remain.  These  challenges  can  be  managed during data analysis.  Scale:  Processing  of  large  and  rapidly  increasing  volumes  of  data  is  a  challenging  task.  Using data processing technologies, the data scale challenge was mitigated by the evolution  of  processing  and  storage  resources.  Nowadays  however  data  volumes  are  scaling  faster  than resources  can  evolve.  Technologies such as parallel databases, in memory databases,  non-SQL databases and analytical algorithms allow this challenge to be resolved. Timeliness:  The acquisition rate and timeliness, to effectively find elements in limited time  that  meet  a  specified  criterion  in  a  large  dataset,  are  new  challenges  faced  by  data  processing. Other new challenges are related to  the  types  of criteria specified and there is a  need to devise new index structures and responses to the queries having tight response time  limits. Privacy:  Data  about  human  individuals,  such  as  demographic  information,  Internet  activities,  commutation  patterns,  social  interactions,  energyThe big  data service provider  (BDSP) supports capabilities for big  data analytics  and infrastructure.  The big  data  service  provider can act as a form of  big  data  platform,  an  extension of  the  existing  data analytics platform, etc. Big data service provider activities include:  searching  data  sources  (from  the  data  broker)  and  collecting  data  by  requesting  and  crawling, storing data to a data repository, integrating data, providing tools for data analysis and visualization, supporting  data  management  such  as  data  provenance,  data  privacy,  data  security,  data  retention policy, data ownership, etc.  or  water  consumption,  are  being collected and analysed for different purposes. Big data technologies and services are  challenged  to  protect  personal  identities  and  sensitive  attributes  of  data  throughout  the  whole data processing cycle while respecting applicable data retention policy. Positive  resolving  of  the  above  challenges  opens  new  opportunities  to  discover  new  data  relationships, hidden patterns or unknown dependencies.  Big data refers  to  technologies and services which extract valuable information from the  extensive datasets  characterized  by  the  Vs,  while  cloud  computing  is,  as  defined  in  [ITU-T Y.3500],  the  paradigm for enabling network access to a scalable and elastic pool of shareable physical or virtual  resources with self-service provisioning and administration on-demand. Big  data  needs  on-demand  high  performance  data  processing  and  distributed  storage  as  well  as  variety of tools required to accomplish activities of the big data  ecosystem which  are  described in  clause 6.2.  Cloud computing meets the challenges of big data as described in clause 6.1.  The burst  nature  of  workloads  makes  cloud  computing  more  appropriate  for  big  data  challenges  such  as  scalability  and  timeliness.  The  big  data  ecosystems,  which  are  supported  by  a  cloud  computing  system context,  can be  referred to  as cloud computing based big data.   This  clause  describes  a  cloud  computing  based  big  data  system  context  that  is  effective  for  supporting big data. It also provides benefits of cloud computing based big data.  Cloud computing based big data system context is described with new sub-roles and activities based  on  the  architectural  user  view  defined  in  [ITU-T  Y.3502].  This  clause  describes  how  cloud  computing can support  the three main roles in  a  big data ecosystem:  data provider, big data service  provider and big data service customer.  Requirements of cloud computing based big data. The data collection requirements include: It  is  required  for  the  CSP:BDIP  to  support  collecting  data  from  multiple  CSN:DPs  in  parallel, It  is  recommended  for  the  CSN:DP  to  expose  data  to  the  CSP:BDAP  by  publishing  metadata, It  is  recommended  that  the  CSP:BDIP  supports  collecting  data  from  different  CSN:DPs  with different modes, NOTE  –  Data could be collected in different modes, such as pull mode in which the  data collection  process is initiated by CSP:BDIP,  or push mode in which the  data collection process is initiated by  It  is  recommended  for  the  CSN:DP  to  provide  a  brokerage  service  to  the  CSP:BDIP  for  searching accessible data, NOTE  –  Brokerage provides data  a  catalog which has  data  information such as data specification,  data instructions, electronic access methods, license policy, data quality, etc. It  is  recommended  that  the  CSP:BDIP  integrates  data  delivered  by  the  CSC  and  data  publicly available, Data collection can optionally be performed by the CSP:BDIP in real-time.  The data analysis requirements include: It is required for the CSP:BDAP to support analysis of various data types and formats, It is required for the CSP:BDAP to support batch processing, It is required for the CSP:BDAP to support association analysis, It is required for the CSP:BDAP to support different data analysis algorithms, NOTE – Data analysis algorithms include classification, clustering, regression, association, ranking, etc. Data collection capabilities include: Data source intelligent recognition, which  offers the capabilities to locate the data sources  and detect the types of data being collected, Data  adaptation,  which  offers  the  capabilities  to  transform  and  organize  the  data  being  collected  with  targeted  data  structures  and  attributes  (numbering,  location,  ownerships,  etc.), Data integration, which offers the capabilities to integrate data from different data sources  (different data types) using metadata or ontology, Data brokerage, which offers the capabilities to provide a brokerage service for searching  data.  Security  aspects  for  consideration  within  cloud  computing  environments,  including  cloud  infrastructure,  IaaS,  NaaS,  DaaS  are  addressed  by  security  challenges  for  CSPs,  as  described  in  [ITU-T  X.1601].  In  particular,  [ITU-T  X.1601]  analyses  security  threats  and  challenges,  and  describes security capabilities that could mitigate these threats and meet security challenges. Relevant security requirements of [b-ITU-T Y.2201], [b-ITU-T Y.2701] and applicable X, Y and M  series  of  ITU-T  Recommendations  need  to  be  taken  into  consideration,  including  access  control,  authentication,  data  confidentiality,  data  retention  policy,  network  security,  data  integrity,  availability and privacy.      